{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fca7ac",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation for Coca-Cola Marketing Mix\n",
    "**A Step-by-Step Guided Case Study**\n",
    "\n",
    "## ðŸ¥¤ Introduction: The Coca-Cola Scenario\n",
    "Welcome! In this class, you are a Business Analyst at Coca-Cola. You don't need to be a programmer to use this tool. Think of the code cells below as \"Engines\" that generate a year of sales data for us.\n",
    "\n",
    "\n",
    "# Step 1. Configuration and Library Installation\n",
    "\n",
    "Before starting, we need to load our tools. This section sets up the required Python libraries. `Faker` is essential for generating realistic, structured categorical IDs (like Campaign IDs and Market Codes), adding a layer of corporate data complexity.\n",
    "\n",
    "Just click the \"Play\" button on the left of the cell below. You don't need to change anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02fd2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just press play!\n",
    "\n",
    "# Install Faker (if necessary)\n",
    "!pip3 install pandas numpy faker seaborn matplotlib\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae79151",
   "metadata": {},
   "source": [
    "ðŸ¤– **Meet \"Faker\": Our Digital Reality Generator**\n",
    "\n",
    "In the business world, we often face a problem: Real data is sensitive. Due to privacy laws (like GDPR) or corporate secrets, we cannot always use real customer names or internal codes for training or testing.\n",
    "\n",
    "Faker is a Python library that acts like a \"digital actor\" factory. It allows us to generate thousands of realistic pieces of information in seconds. Here you have some interesting links:\n",
    "- [Faker Documentation](https://faker.readthedocs.io/en/master/#)\n",
    "- [Faker Example 1](https://www.datacamp.com/tutorial/creating-synthetic-data-with-python-faker-tutorial)\n",
    "- [Faker Example 2](https://www.geeksforgeeks.org/python/python-faker-library/)\n",
    "\n",
    "Business Note: In your future career, tools like Faker are essential for creating \"Prototypes\" or \"Demos\" of products before you have real customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ff61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Faker\n",
    "fake = Faker('en_US')\n",
    "print(\"âœ… Our generator is ready to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times to see different fake identities!\n",
    "print(f\"Fake Employee Name: {fake.name()}\")\n",
    "print(f\"Fake Warehouse Address: {fake.address()}\")\n",
    "print(f\"Fake Business Email: {fake.company_email()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0726e",
   "metadata": {},
   "source": [
    "Before we build our Coca-Cola dataset, let's learn how to generate data.\n",
    "\n",
    "To use this tool, you need to understand its structure:\n",
    "\n",
    "1. **The Generator (fake)**: This is the main tool.\n",
    "\n",
    "2. **Providers**: These are like \"departments\" (e.g., the Address department, the Job department).\n",
    "\n",
    "3. **Generator Properties**: These are the specific \"items\" you can get, like a name or a color.\n",
    "\n",
    "**Key Rule**: Each of the generator properties (like `name`, `address`, and `email`) are called \"fake\". A faker generator has many of them, packaged in \"providers\".\n",
    "\n",
    "ðŸ” **Exercise**: The Provider Hunt\n",
    "Your task is to visit the [Faker Documentation](https://faker.readthedocs.io/en/master/providers.html) and find the right \"Property\" to fill the \"Secret Agent Passport\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b41ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TODO: ---\n",
    "# Replace the ???? with the correct property from the documentation\n",
    "\n",
    "print(\"ðŸ•µï¸ SECRET AGENT PASSPORT\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. Use the 'Person' provider\n",
    "print(f\"FULL NAME: {fake.name()}\")\n",
    "\n",
    "# 2. Find the property for a full credit card number in the 'Credit Card' provider\n",
    "print(f\"SAFE HOUSE: {fake.????()}\") \n",
    "\n",
    "# 3. Find the property for a job in the 'Job' provider\n",
    "print(f\"COVER JOB: {fake.????()}\") \n",
    "\n",
    "# 4. Find the property for a company name in the 'Company' provider\n",
    "print(f\"FRONT COMPANY: {fake.????()}\") \n",
    "\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe5084",
   "metadata": {},
   "source": [
    "Now that we know how to generate synthetic data, let's return to our **Coca-Cola** use case.\n",
    "\n",
    "This notebook contains the Python code to generate a synthetic dataset for a Marketing Mix Modeling (MMM) scenario, incorporating Time Series variables, regulatory impact (Legal), and segmentation (Computer Science/Marketing). The final dataset contains the columns that you can see below:\n",
    "\n",
    "| Variable (Field)        | Data Type             | Description                                                                                                   | Key Discipline Focus              |\n",
    "|-------------------------|-----------------------|---------------------------------------------------------------------------------------------------------------|-----------------------------------|\n",
    "| Date                    | Date                  | Observation date (daily granularity over 365 days).                                                            | Computer Science (Time Series)    |\n",
    "| Market_Code             | Categorical (String)  | Internal, synthetic market code for the region (e.g., MK-N01). Generated using Faker.                          | Computer Science / Marketing      |\n",
    "| Region                  | Categorical           | Geographic segmentation: North, South, Central, East.                                                          | Marketing / Legal                 |\n",
    "| Product_Flavor          | Categorical           | Specific product variant: Classic, Vanilla_Zero, Cherry_Zero, Mango_Zero.                                     | Marketing                         |\n",
    "| Campaign_ID             | Categorical (String)  | Identifier for the campaign period (e.g., SPR-#### for Spring campaign). Generated using Faker.                | Marketing                         |\n",
    "| Sugar_Tax_Regulation    | Binary (0/1)          | Regulatory flag: 1 if the region has a strict sugar tax or regulation; 0 otherwise. Critical for Legal Analysis.| Legal                             |\n",
    "| Customer_Segment_ID     | Integer (1-4)         | Synthetic cluster ID assigned to the consumer base in that market/day.                                         | Computer Science (Clustering)     |\n",
    "| Ad_Impressions          | Integer               | Daily volume of digital advertising impressions served in the market. Simulates campaign spikes.              | Marketing                         |\n",
    "| Promo_Type              | Categorical           | Type of promotional activity active that day: None, Discount_10, BOGO.                                        | Marketing                         |\n",
    "| Competitor_Price_Index  | Numeric (Float)       | Price of the main competitor relative to Coca-Cola (1.0 = price parity).                                      | Marketing                         |\n",
    "| Avg_Social_Sentiment    | Numeric (Float)       | Average sentiment score (0 to 1) towards the campaign/brand on social media that day.                          | Computer Science / Marketing      |\n",
    "| Hashtag_Mentions        | Integer               | Daily count of relevant hashtag mentions on social media platforms.                                            | Computer Science / Marketing      |\n",
    "| Sales_Volume            | Integer               | TARGET VARIABLE: Total units of the specific Product_Flavor sold daily in the Region.                          | Computer Science / Marketing      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab434814",
   "metadata": {},
   "source": [
    "# Step 2. Defining our regions\n",
    "\n",
    "We define the core constants for the Marketing Mix Modeling (MMM) scenario. \n",
    "\n",
    "We operate in 4 regions. Some regions (South and East) have a Sugar Tax, meaning the government charges extra for sugary drinks. This will affect how much we sell.\n",
    "\n",
    "Note the **`SUGAR_TAX_REGIONS`** array; this is a critical input that links the Legal and Computer Science domains, as it will be used to penalize the 'Classic' flavor's sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION AREA\n",
    "# Here we define the basic 'rules' of our market: regions and flavors\n",
    "N_DAYS = 365 \n",
    "REGIONS = ['North', 'South', 'Central', 'East']\n",
    "FLAVORS = ['Classic', 'Vanilla_Zero', 'Cherry_Zero', 'Mango_Zero']\n",
    "\n",
    "print(f\"Market defined: {len(REGIONS)} Regions and {len(FLAVORS)} Flavors across {N_DAYS} days.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TODO: ---\n",
    "# Instructions: Edit the list below to define which regions have strict sugar regulations.\n",
    "# Make sure the names match exactly: 'North', 'South', 'Central', or 'East'.\n",
    "SUGAR_TAX_REGIONS = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f1b80",
   "metadata": {},
   "source": [
    "# Step 3. Creating the basic structure of data\n",
    "\n",
    "Now we will generate a list of daily sales. We will use `Faker` to create realistic \"Market Codes\" for each region so our database looks professional. First we will create the basic structure of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS = N_DAYS * len(REGIONS) * len(FLAVORS)\n",
    "print(f\"Total rows to generate (Day * Region * Flavor): {N_ROWS}\\n\")\n",
    "\n",
    "# Create the base matrix (Date, Region, Flavor)\n",
    "dates = pd.date_range(start='2024-01-01', periods=N_DAYS, freq='D')\n",
    "base_df = pd.DataFrame([(d, r, f) for d in dates for r in REGIONS for f in FLAVORS],\n",
    "                       columns=['Date', 'Region', 'Product_Flavor'])\n",
    "\n",
    "print(base_df.head()) # Check the base structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b9e76",
   "metadata": {},
   "source": [
    "# Step 4. Marketing Impact\n",
    "We use custom logic and `Faker` to generate the foundational columns, focusing on identifiers and the regulatory binary variable.\n",
    "\n",
    "In a large company like Coca-Cola, marketing actions are organized by **Campaign IDs**. These are unique codes (like SPR-4921) used by the Finance and Marketing departments to track how much money was spent and earned during a specific period.\n",
    "\n",
    "We have designed a \"Smart Labeler\" (a function) that looks at the date of every single sale and decides if it belongs to a special campaign:\n",
    "\n",
    "- Spring Campaign (March & April): Labeled as SPR-####\n",
    "- Summer Campaign (July & August): Labeled as SMR-####\n",
    "- Regular Days: Labeled as BASE-0000\n",
    "\n",
    "**The Magic** of bothify\n",
    "\n",
    "To make it look real, we use a `Faker` property called `bothify`.\n",
    "\n",
    "- It takes a pattern like SPR-####.\n",
    "- It automatically replaces every # with a random number.\n",
    "- This creates a unique, professional-looking ID for our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Faker Integration for Realism ---\n",
    "def generate_campaign_ids(df):\n",
    "    campaign_ids = []\n",
    "    id_spring = fake.bothify(text='SPR-####')\n",
    "    id_summer = fake.bothify(text='SMR-####')\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        month = row['Date'].month\n",
    "        if month in [3, 4]:\n",
    "            campaign_ids.append(id_spring)\n",
    "        elif month in [7, 8]:\n",
    "            campaign_ids.append(id_summer)\n",
    "        else:\n",
    "            campaign_ids.append('BASE-0000')\n",
    "    return campaign_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af101a48",
   "metadata": {},
   "source": [
    "Now we run the code and save the results in a new column called **`Campaign_ID`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df['Campaign_ID'] = generate_campaign_ids(base_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c664151",
   "metadata": {},
   "source": [
    "In professional databases, regions are rarely identified only by their names (like \"North\"). They usually have a Market Code for internal logistics, accounting, and supply chain tracking.\n",
    "\n",
    "In this step, we are doing two things:\n",
    "\n",
    "1. **Creating a Dictionary**: We build a \"translation table\" that says: \"For the North region, the code will be MK-N[Random Numbers]\".\n",
    "\n",
    "2. **Mapping the Table**: We tell the computer to look at our big sales table and, wherever it sees \"North\", \"South\", etc., add its corresponding unique code.\n",
    "\n",
    "How the code works:\n",
    "* `r[0].upper()`: This tells Python: \"Take the first letter of the Region and make it Capital\" (N for North, S for South).\n",
    "\n",
    "* `'MK-' + ... + '##'`: This creates a pattern or \"template\" like MK-N##.\n",
    "\n",
    "* `fake.bothify`: As you learned before, this replaces the ## with random numbers (e.g., MK-N12).\n",
    "\n",
    "* `.map()`: This is the command that performs the \"translation\" for all rows in our table at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e994080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MARKET CODE GENERATION ---\n",
    "# This part creates the \"Translation Dictionary\"\n",
    "# Format: { 'RegionName': 'MK-Letter##' }\n",
    "market_code_map = {r: fake.bothify(text='MK-' + r[0].upper() + '##') for r in REGIONS}\n",
    "base_df['Market_Code'] = base_df['Region'].map(market_code_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217dfd6b",
   "metadata": {},
   "source": [
    "In data analysis, we often need to translate a complex reality into a simple binary format (1 or 0). This methodology will be used for variable **`Sugar_Tax_Regulation`**. This variable links the Legal domain to the data, as it will directly impact the target variable. Possible values will be:\n",
    "\n",
    "* 1: Yes, this condition is true (The region has a Sugar Tax).\n",
    "\n",
    "* 0: No, this condition is false (The region has no tax).\n",
    "\n",
    "This allows the computer to perform mathematical operations later. For example, if we want to penalize sales by 20%, we can multiply by this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b7134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LEGAL REGULATION FILTER ---\n",
    "\n",
    "# This line creates our binary 'Yes/No' column (1 or 0)\n",
    "# 'lambda r' is just a way to say: \"For every region (r) in our list...\"\n",
    "base_df['Sugar_Tax_Regulation'] = base_df['Region'].apply(lambda r: 1 if r in SUGAR_TAX_REGIONS else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b9640",
   "metadata": {},
   "source": [
    "Finally, in marketing, treating every customer exactly the same is a mistake. A teenager buying a single can of Cherry Zero at a gas station is not the same as a parent buying three 24-packs of Classic Coke at a supermarket.\n",
    "\n",
    "Column **`Customer_Segment_ID`**, acts as a crucial bridge between simple data collection and advanced Artificial Intelligence; while we are currently assigning every sale to one of four groups (1 to 4) randomly, this field represents the \"hooks\" that marketing teams use to perform Clustering, allowing you in the future to replace these random numbers with real consumer profiles (such as \"Budget Shoppers\" or \"Health-Conscious Teens\"), to analyze if certain segments are more loyal to specific flavors or more sensitive to price changes and government regulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CUSTOMER SEGMENTATION ---\n",
    "# We generate a random ID between 1 and 4 for every row (N_ROWS)\n",
    "# These represent different 'types' of shoppers\n",
    "base_df['Customer_Segment_ID'] = np.random.randint(1, 5, N_ROWS)\n",
    "\n",
    "print(base_df.head())  # Check the updated structure with new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c9b6d",
   "metadata": {},
   "source": [
    "# Step 5. Generation of Marketing Mix and Digital Variables\n",
    "\n",
    "In business, sales don't just happen by accident, they are driven by specific actions. This step simulates our Marketing Mixâ€”the levers we pull to convince customers to buy a Coke.\n",
    "\n",
    "The first variable we will use to model this will be **`Campaign_ID`**. This variable will measure the number of impressions a campaign has had among the public.\n",
    "\n",
    "\n",
    "Why are we **\"spiking\"** the Ads?\n",
    "We will implement the code to intentionally \"spike\" our Digital Ad Impressions during the Spring and Summer campaigns.\n",
    "\n",
    "* Normal days: Between 1,000 and 5,000 views.\n",
    "\n",
    "* Spring Campaign: Boosted up to 15,000 views.\n",
    "\n",
    "* Summer Campaign: Boosted up to 20,000 views.\n",
    "\n",
    "We do this because a good analyst needs to see \"contrast\" in the data. If we spent the same amount on ads every single day, we would never know if the ads actually work! By creating these peaks, we can later prove the Return on Investment (ROI) of our marketing budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ce456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MARKETING MIX GENERATION ---\n",
    "\n",
    "# 1. We start with a baseline of random daily ad views\n",
    "base_df['Ad_Impressions'] = np.random.randint(1000, 5000, N_ROWS)\n",
    "\n",
    "# 2. We \"Inject\" the Campaign Spikes\n",
    "peak_spring = base_df['Campaign_ID'].str.contains('SPR')\n",
    "peak_summer = base_df['Campaign_ID'].str.contains('SMR')\n",
    "\n",
    "base_df.loc[peak_spring, 'Ad_Impressions'] = np.random.randint(5000, 15000, peak_spring.sum())\n",
    "\n",
    "# --- TODO: ---\n",
    "# Replace the ???? with the correct code to inject summer campaign spikes\n",
    "base_df.loc[peak_summer, 'Ad_Impressions'] = ????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b8620",
   "metadata": {},
   "source": [
    "Secondly, we define two critical business variables that directly influence a customer's decision at the point of sale:\n",
    "\n",
    "* **`Promo_Type`**: We have three options: None (regular price), Discount_10 (10% off), and BOGO (Buy One Get One Free).\n",
    "    * We use a probability distribution p=[0.7, 0.2, 0.1]. This means that in our simulation, 70% of the time there is no promo, 20% of the time we offer a discount, and only 10% of the time we run a BOGO campaign.\n",
    "\n",
    "* **`Competitor_Price_Index`**: This is a benchmark.\n",
    "    * A value of 1.0 means our price is identical to our competitors.\n",
    "\n",
    "    * Values below 1.0 mean we are cheaper (more competitive).\n",
    "\n",
    "    * Values above 1.0 mean we are more expensive (premium positioning).\n",
    "\n",
    "    * We use np.random.uniform(0.8, 1.2) to simulate a realistic market where prices fluctuate daily within a +/- 20% range.\n",
    "\n",
    "This two features allow the model to reflect a realistic environment where our sales are constantly pressured by how our prices compare to rivals like Pepsi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PROMOTION AND PRICING STRATEGY ---\n",
    "\n",
    "# 1. Define the types of promotions available\n",
    "PROMOS = ['None', 'Discount_10', 'BOGO']\n",
    "\n",
    "# 2. Assign promotions to each day based on our strategy:\n",
    "# 70% None, 20% Discount, 10% BOGO\n",
    "base_df['Promo_Type'] = np.random.choice(PROMOS, N_ROWS, p=[0.7, 0.2, 0.1])\n",
    "\n",
    "# 3. Generate a Price Index compared to competitors (between 0.8 and 1.2)\n",
    "# We round to 2 decimals for a cleaner \"Price Tag\"\n",
    "base_df['Competitor_Price_Index'] = np.random.uniform(0.8, 1.2, N_ROWS).round(2)\n",
    "\n",
    "# Final check\n",
    "print(\"Promotion and Pricing variables successfully applied!\")\n",
    "# Let's see how they distributed\n",
    "base_df['Promo_Type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e590cdd0",
   "metadata": {},
   "source": [
    "In modern marketing, we don't just look at our own ads, we look at what the internet says about us. We are going to generate two \"Digital Signals\":\n",
    "\n",
    "* **`Avg_Social_Sentiment`**: This represents the mood of the internet.\n",
    "\n",
    "    * Values close to 0.9 mean the brand is trending positively (everyone loves the new ad!).\n",
    "\n",
    "    * Values close to 0.1 mean there is a public relations crisis.\n",
    "\n",
    "    * We use a Normal Distribution (Bell Curve) because most days are just \"normal\" (around 0.6).\n",
    "\n",
    "* **`Hashtag_Mentions`**: This represents the volume of conversation (How many times #CocaCola was used).\n",
    "**Instructions:**\n",
    "1. Research: Go to the [Official NumPy Documentation for Poisson](https://numpy.org/doc/stable/reference/random/generated/numpy.random.poisson.html).\n",
    "\n",
    "2. Find the Parameter: Look for the parameter that represents the \"interval average\" (often called lambda or lam).\n",
    "\n",
    "3. Implement: In the code below, replace the ???? with the correct function and parameters.\n",
    "\n",
    "    * The average number of mentions should be 20.\n",
    "\n",
    "    * The size of the data should be N_ROWS (which we defined at the beginning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8361531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DIGITAL INPUTS ---\n",
    "\n",
    "# 1. Social Sentiment (The \"Mood\" of the internet)\n",
    "# Most days it's around 0.6 (Normal distribution)\n",
    "base_df['Avg_Social_Sentiment'] = np.random.normal(loc=0.6, scale=0.15, size=N_ROWS).clip(0.1, 0.9)\n",
    "\n",
    "# TODO: Change the 'lam' (lambda) value to increase or decrease daily mentions\n",
    "base_df['Hashtag_Mentions'] = np.random.????(lam=??, size=N_ROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0a45b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TEST YOUR CODE ---\n",
    "if 'Hashtag_Mentions' in base_df.columns:\n",
    "    print(\"âœ… Great job! You've generated the digital signal.\")\n",
    "    print(f\"Average mentions generated: {base_df['Hashtag_Mentions'].mean():.2f}\")\n",
    "    # Show the 'spikes' of virality\n",
    "    base_df['Hashtag_Mentions'].plot(kind='hist', title='Distribution of Hashtag Mentions', bins=20)\n",
    "else:\n",
    "    print(\"âŒ The column 'Hashtag_Mentions' is missing. Keep investigating!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0fb39",
   "metadata": {},
   "source": [
    "# Step 6. Generation of the Target Variable (`Sales_Volume`)\n",
    "\n",
    "This is the most critical section. `Sales_Volume` is generated as a complex, non-linear function of all inputs.\n",
    "\n",
    "The core dependencies include:\n",
    "1.  **Seasonality:** Higher sales in summer months.\n",
    "2.  **Marketing Mix:** Multiplicative effect from promotions (`BOGO` > `Discount`).\n",
    "3.  **Ad Impressions:** Logarithmic (non-linear) additive effect, simulating diminishing returns.\n",
    "4.  **Regulatory Impact (Legal):** A **25% penalty** is applied to `Classic` sales in regions where `Sugar_Tax_Regulation` = 1.\n",
    "\n",
    "Before we calculate the impact of our marketing campaigns or the sugar tax, we need to establish a **Baseline**. This represents what Coca-Cola would sell on an average day, with no special events or regulations. In this initial phase of our sales modeling, we establish a Baseline by generating a \"natural\" sales volume using a Normal Distribution, which provides a realistic starting point centered around an average of 1,500 daily units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BASELINE SALES GENERATION ---\n",
    "\n",
    "# We generate the \"natural\" sales for every day in our dataset\n",
    "base_sales = np.random.normal(loc=1500, scale=300, size=N_ROWS)\n",
    "sales_volume = base_sales\n",
    "\n",
    "print(f\"âœ… Baseline sales generated. {sales_volume.mean():.2f} average sales before seasonality.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4051dec1",
   "metadata": {},
   "source": [
    "In the beverage industry, the weather is one of our most powerful \"silent\" sales agents. When the temperature rises, so does the thirst of our consumers. In analytics, we call this **Seasonality**.\n",
    "\n",
    "To reflect this reality in our data, we apply a \"Summer Factor\":\n",
    "\n",
    "* The Logic: The code identifies the months of June (6), July (7), and August (8).\n",
    "\n",
    "* The Multiplier: We add a 40% boost (0.4 + 1.0 = 1.4) to the baseline sales during these months.\n",
    "\n",
    "* The Result: If a normal day sells 1,500 units, a summer day will automatically jump to 2,100 units just because of the calendar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9948e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- APPLYING SEASONALITY ---\n",
    "\n",
    "# 1. Identify rows that fall in June, July, or August\n",
    "# This creates a 'multiplier' (1.4 for summer, 1.0 for the rest of the year)\n",
    "summer_factor = base_df['Date'].dt.month.isin([6, 7, 8]) * 0.4 + 1.0\n",
    "\n",
    "# 2. Multiply our baseline sales by this factor\n",
    "sales_volume *= summer_factor\n",
    "print(f\"âœ… Seasonality applied: Summer sales boost included. {sales_volume.mean():.2f} average sales after seasonality.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c953f4",
   "metadata": {},
   "source": [
    "Marketing isn't just one thing, it's a combination of \"levers\" we pull to increase demand. In this step, we simulate two of the most common ones:\n",
    "\n",
    "1. **Promotion Power (Multiplicative)**: We use a \"mapping\" to scale sales based on the offer:\n",
    "\n",
    "    * Discount_10: Boosts sales by 25% (multiplier of 1.25).\n",
    "\n",
    "    * BOGO: Boosts sales by 55% (multiplier of 1.55).\n",
    "\n",
    "    * None: Sales stay at 100% (multiplier of 1.0).\n",
    "\n",
    "2. **The Ad Effect (Logarithmic)**: We add the influence of our Digital Ad Impressions.\n",
    "\n",
    "    * We use a Logarithm (np.log) because of the \"Law of Diminishing Returns.\"\n",
    "\n",
    "    * The first 1,000 ads have a huge impact, but the difference between 1,000,000 and 1,001,000 ads is almost invisible. This prevents our simulation from creating \"infinite sales\" just by spending more money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6438d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- APPLYING PROMOTIONS & ADVERTISING ---\n",
    "\n",
    "# 1. Map each promo type to its specific sales boost\n",
    "promo_map = {'None': 1.0, 'Discount_10': 1.25, 'BOGO': 1.55}\n",
    "sales_volume *= base_df['Promo_Type'].map(promo_map)\n",
    "\n",
    "# 2. Add the impact of digital ads (using a log scale to be realistic)\n",
    "sales_volume += np.log(base_df['Ad_Impressions'] + 1) * 35 \n",
    "\n",
    "print(\"Marketing Mix applied! We can now see how promos and ads drive the volume.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214cba21",
   "metadata": {},
   "source": [
    "In business, your price is only \"expensive\" or \"cheap\" compared to your neighbor. This step introduces **Competitive Pressure**.\n",
    "\n",
    "We use the **`Competitor_Price_Index`** to adjust our sales volume using an inverse relationship:\n",
    "\n",
    "* If the Index is 1.2 (We are 20% more expensive): Our sales will suffer because customers might switch to a cheaper brand.\n",
    "\n",
    "* If the Index is 0.8 (We are 20% cheaper): Our sales will increase as we \"steal\" market share.\n",
    "\n",
    "The Formula Logic: We use (Index * 0.5 + 0.5) to smooth the impact.\n",
    "\n",
    "* This ensures that even if our price is high, sales don't drop to zero instantly, reflecting real-world Brand Loyalty. People still buy Coca-Cola even if it's slightly more expensive than a generic brand, but they buy less of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- COMPETITOR PRICE EFFECT ---\n",
    "\n",
    "# We adjust the volume based on how our price compares to the market\n",
    "# High Index (>1.0) = Lower Sales | Low Index (<1.0) = Higher Sales\n",
    "sales_volume *= (base_df['Competitor_Price_Index'] * 0.5 + 0.5) \n",
    "\n",
    "print(\"Competitive effect applied. The market is now reacting to our pricing strategy.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b485b2d8",
   "metadata": {},
   "source": [
    "n the digital age, a brand's health isn't just measured by clicks, but by **how people feel**. This step adds the \"Digital Halo\" effect to our sales volume.\n",
    "\n",
    "* **Quality over Quantity**: While Ad_Impressions measured how many people saw us, Avg_Social_Sentiment measures if they actually like us.\n",
    "\n",
    "* **Direct Impact**: We multiply the sentiment score (from 0.1 to 0.9) by 150 units.\n",
    "\n",
    "    * If the internet is \"on fire\" with positive comments (0.9), we add 135 extra units per day.\n",
    "\n",
    "    * If there is a PR crisis (0.1), we only add 15 units.\n",
    "\n",
    "This simulates a world where a good reputation acts as a sales accelerator, rewarding the brand when the community is happy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e74662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DIGITAL SENTIMENT EFFECT ---\n",
    "\n",
    "# A higher sentiment score directly adds more units to our daily volume\n",
    "sales_volume += base_df['Avg_Social_Sentiment'] * 150\n",
    "\n",
    "print(\"Digital reputation applied! The 'mood' of the internet is now impacting our bottom line.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b6d77",
   "metadata": {},
   "source": [
    "This is the most critical part of the simulation for the **Legal Department**. Here, we apply the \"real-world\" consequences of the sugar tax regulations we defined earlier. Notice how the law doesn't affect everyone equally: it creates winners and losers.\n",
    "\n",
    "1. **The Penalty (Classic Coke)**: For our Classic flavor in regulated regions, we apply a 25% sales cut (* 0.75). This simulates how higher prices (due to the tax) or health warnings drive consumers away.\n",
    "\n",
    "2. **The Opportunity (Zero Sugar)**: For products containing Zero in their name, we apply a 5% boost (* 1.05) in those same regions. This simulates \"Substitution Bias\"â€”consumers who want a soda but switch to the healthier, non-taxed option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112996f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- APPLYING LEGAL REGULATION IMPACT ---\n",
    "\n",
    "# 1. Identify \"Classic\" sales in Taxed Regions (The Losers)\n",
    "is_classic_and_taxed = (base_df['Product_Flavor'] == 'Classic') & (base_df['Sugar_Tax_Regulation'] == 1)\n",
    "sales_volume[is_classic_and_taxed] *= 0.75 \n",
    "\n",
    "# 2. Identify \"Zero\" sales in Taxed Regions (The Winners)\n",
    "is_zero_and_taxed = (base_df['Product_Flavor'].str.contains('Zero')) & (base_df['Sugar_Tax_Regulation'] == 1)\n",
    "sales_volume[is_zero_and_taxed] *= 1.05 \n",
    "\n",
    "print(\"Legal impact applied! The regulation has reshaped our sales landscape.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6768e",
   "metadata": {},
   "source": [
    "In the real world, even if you follow every formula, sales will never be exactly what you predicted. A truck might break down, a local festival might boost sales unexpectedly, or a fridge in a supermarket might stop working.\n",
    "\n",
    "To make our data truly professional, we add two final touches:\n",
    "\n",
    "1. **Random Noise**: We add a small amount of \"randomness\" (np.random.normal(0, 100)). This ensures that two days with the exact same ads, price, and weather still have slightly different sales. It's the \"human factor.\"\n",
    "\n",
    "2. **The Floor (Safety Logic)**: Since it is mathematically impossible to have \"negative sales\" (you can't sell -50 Cokes), we use np.maximum(0, ...) to ensure that the lowest possible value is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed480b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FINAL REFINEMENT ---\n",
    "\n",
    "# 1. Add final \"Market Noise\" (standard fluctuation)\n",
    "sales_volume += np.random.normal(0, 100, N_ROWS)\n",
    "\n",
    "# 2. Convert to integers (you can't sell half a bottle) \n",
    "# and ensure no negative values exist\n",
    "base_df['Sales_Volume'] = np.maximum(0, sales_volume.astype(int))\n",
    "\n",
    "print(\"Sales_Volume generated with injected correlations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f79b49",
   "metadata": {},
   "source": [
    "# Step 7. Coherence Validation and Documentation\n",
    "\n",
    "Before handing the data off, the CS team must validate that the injected logic works. The validation check below is essential for the **Legal** team, as it visually quantifies the economic effect of the `Sugar_Tax_Regulation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns for presentation and saving\n",
    "final_cols = ['Date', 'Market_Code', 'Region', 'Product_Flavor', 'Campaign_ID',\n",
    "              'Sugar_Tax_Regulation', 'Customer_Segment_ID',\n",
    "              'Ad_Impressions', 'Promo_Type', 'Competitor_Price_Index',\n",
    "              'Avg_Social_Sentiment', 'Hashtag_Mentions', 'Sales_Volume']\n",
    "\n",
    "synthetic_data = base_df[final_cols]\n",
    "\n",
    "print(\"\\n--- Final Dataframe (Head) ---\")\n",
    "display(synthetic_data.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079509c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- COHERENCE VALIDATION (CS/Legal Task) ---\n",
    "print(\"\\n--- Regulatory Impact Validation (Average Sales) ---\")\n",
    "validation_check = synthetic_data.groupby(['Product_Flavor', 'Sugar_Tax_Regulation'])['Sales_Volume'].mean().unstack()\n",
    "print(\"Average 'Classic' sales SHOULD be lower where Sugar_Tax_Regulation=1.\")\n",
    "print(\"Average 'Zero' sales SHOULD be higher where Sugar_Tax_Regulation=1.\")\n",
    "display(validation_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save the dataset ---\n",
    "#synthetic_data.to_csv('coca_cola_marketing_mix_synthetic_data_faker.csv', index=False)\n",
    "print(\"\\nDataset successfully saved as 'coca_cola_marketing_mix_synthetic_data_faker.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f064bdb4",
   "metadata": {},
   "source": [
    "# 7. Basic Visualization Task\n",
    "\n",
    "These visualizations serve as the final validation check, ensuring the data structure is robust and the correlations are visible before moving to advanced modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab97d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Example 1: Validate Promotion Effect (Marketing Mix)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x='Promo_Type', y='Sales_Volume', data=synthetic_data, order=PROMOS)\n",
    "plt.title('Sales Volume vs. Promotion Type (Validation)')\n",
    "plt.ylabel('Sales Volume (Units)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde07acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Example 2: Validate Regulatory Effect (Legal)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x='Product_Flavor', y='Sales_Volume', hue='Sugar_Tax_Regulation', data=synthetic_data)\n",
    "plt.title('Regulatory Impact on Sales by Flavor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ea1db",
   "metadata": {},
   "source": [
    "The **Seasonality Trend**: Does the \"Summer Boost\" actually show up in the calendar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b92139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Example 3: Monthly Sales Trend\n",
    "plt.figure(figsize=(12, 5))\n",
    "base_df.set_index('Date').resample('M')['Sales_Volume'].sum().plot(marker='o', color='red', linewidth=2)\n",
    "plt.title('Monthly Total Sales (Seasonality Validation)', fontsize=14)\n",
    "plt.ylabel('Units Sold')\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9960510",
   "metadata": {},
   "source": [
    "**Marketing ROI**: Are we getting diminishing returns on our ad spend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348d9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Example 4: Sales vs. Ad Impressions (Diminishing Returns)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.regplot(x='Ad_Impressions', y='Sales_Volume', data=base_df, \n",
    "            logx=True, scatter_kws={'alpha':0.2, 'color':'gray'}, line_kws={'color':'red'})\n",
    "plt.title('Marketing Effectiveness: The Law of Diminishing Returns', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f6a7bf",
   "metadata": {},
   "source": [
    "The **Correlation Matrix**: Which variable has the strongest \"hidden\" link to our sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9898ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Example 5: The Business \"Drivers\"\n",
    "plt.figure(figsize=(8, 6))\n",
    "cols_of_interest = ['Sales_Volume', 'Ad_Impressions', 'Competitor_Price_Index', 'Avg_Social_Sentiment', 'Hashtag_Mentions']\n",
    "correlation_matrix = base_df[cols_of_interest].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Business Variable Correlation Matrix', fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
